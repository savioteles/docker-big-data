{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark\n",
    "O Apache Spark é um mecanismo de análise unificado para processamento de dados em grande escala com módulos integrados para SQL, streaming, machine learning e processamento de grafos. O Apache Spark é uma estrutura de processamento paralelo de código aberto que oferece suporte ao processamento na memória para aumentar o desempenho de aplicativos que analisam big data. As soluções de big data são projetadas para lidar com dados muito grandes ou complexos para bancos de dados tradicionais. O Spark processa grandes quantidades de dados na memória, o que é muito mais rápido do que as alternativas baseadas em disco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Escrita de arquivos\n",
    "\n",
    "Neste tutorial iremos ler o arquivo [censo_estado.csv](https://raw.githubusercontent.com/savioteles/big_data/master/etl/datasets/censo_estado.csv) que está no meu github e escrever o conteúdo no HDFS utilizando o motor de processamento do Spark.\n",
    "\n",
    "O Spark possui um módulo `SparkFiles` que realiza o download do arquivo e armazena localmente em uma pasta. O código abaixo realiza esta operação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles\n",
    "url = \"https://raw.githubusercontent.com/savioteles/big_data/master/etl/datasets/censo_estado.csv\"\n",
    "spark.sparkContext.addFile(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `get` de `SparkFiles` pega o caminho para o arquivo que o Spark realizou o download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = SparkFiles.get(\"censo_estado.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo faz a leitura do arquivo *censo_estado.csv*:\n",
    "\n",
    "- O arquivo é lido do caminho definido em `file_path`. O prefixo `file://` é para informar para o Spark que o arquivo está no disco local.\n",
    "- O argumento `header=True` informa ao Spark que o arquivo csv tem cabeçalho.\n",
    "- O argumento `inferSchema=True` diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"file://\"+file_path, header=True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `show` apresenta na tela o conteúdo do DataFrame Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A última etapa é escrever o arquivo no formato csv no HDFS. Para isto informamos o caminho do arquivo no HDFS e o prefixo `hdfs://` para que o Spark saiba que o arquivo deve ser escrito no HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv(\"hdfs:///user/hdfs/censo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa\n",
    "\n",
    "Nesta atividade você deve ler um arquivo csv a partir de uma URL e escrever no HDFS:\n",
    "\n",
    "- Primeiro leia o arquivo csv em https://raw.githubusercontent.com/savioteles/big_data/master/etl/datasets/rouanet.csv\n",
    "- Escreve o arquivo no HDFS em `hdfs:///user/hdfs/rouanet.csv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

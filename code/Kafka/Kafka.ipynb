{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka\n",
    "\n",
    "O Apache Kafka é uma plataforma de streaming distribuída de software livre que pode ser usada para compilar pipelines e aplicativos de dados de streaming em tempo real. O Kafka também fornece funcionalidade de agente de mensagem semelhante a uma fila de mensagens, onde você pode publicar e assinar os fluxos de dados nomeados.\n",
    "\n",
    "A API de produtor do Kafka permite que os aplicativos enviam fluxos de dados para o cluster Kafka. A API de consumidor do Kafka permite que os aplicativos leiam fluxos de dados do cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste tutorial, você irá aprender como criar produtores e consumidores para clusters Kafka utilizando Python. Iremos instalar a biblioteca `confluent-kafka` que irá nos permitir utilizar a API do Kafka em Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produtor\n",
    "\n",
    "O produtor se comunica com os hosts de agente de Kafka (nós de trabalho) e envia dados a um tópico Kafka.\n",
    "\n",
    "No código abaixo importamos a classe `Producer` para enviar mensagens para o Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos produzir mensagens *fake* para o tópico do Kafka. Por isso, iremos utilizar a biblioteca faker do Python que gera nomes, endereços, cidades, etc... fakes para podermos construir uma mensagem *fake*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo as bibliotecas são importadas para serem utilizadas no Produtor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos o objeto Faker que será utilizado para criar dados *fake*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake=Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para criar um produtor de mensagens, devemos informar onde está o cluster do Kafka. Para isto definimos em `bootstrap.servers` o IP e porta do cluster do Kafka. Neste tutorial, o IP é *kafka* e a porta *9092*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer=Producer({'bootstrap.servers':'kafka:9092'})\n",
    "print('Kafka Producer foi inicializado...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de mensagens\n",
    "\n",
    "Neste tutorial iremos enviar 10 mensagens para o tópico `usuarios` do Kafka. Iremos enviar uma mensagem com os seguintes campos:\n",
    "\n",
    "- id_usuario\n",
    "- nome_usuario\n",
    "- endereco_usuario\n",
    "- platforma\n",
    "- data_cadastro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # constroi o JSON que será enviado como mensagem\n",
    "    data={\n",
    "       'id_usuario': fake.random_int(min=20000, max=100000),\n",
    "       'nome_usuario':fake.name(),\n",
    "       'endereco_usuario':fake.street_address() + ' | ' + fake.city() + ' | ' + fake.country_code(),\n",
    "       'platforma': random.choice(['Celular', 'Notebook', 'Tablet']),\n",
    "       'data_cadastro': str(fake.date_time_this_month())    \n",
    "       }\n",
    "    # converte o JSON para string para ser enviado no Kafka\n",
    "    m=json.dumps(data)\n",
    "    # publica a mensagem no tópico 'usuarios' com codificação UTF-8\n",
    "    producer.produce('usuarios', m.encode('utf-8'))\n",
    "\n",
    "# faz um flush das mensagens\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumidor\n",
    "\n",
    "O consumidor se comunica com os hosts de broker Kafka (nós de trabalho) e consome as mensagens de um tópico. O primeiro passo é carregar a classe `Consumer` que será utilizada para consumir mensagens da API do Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo passo é consumir mensagens do Kafka. Para isto, passamos três parâmetros para o `Consumer`:\n",
    "\n",
    "- `bootstrap.servers`: ip e porta do Kafka. Aqui o IP é *kafka* e a porta *9092*.\n",
    "- `group.id`: identificador do grupo de consumidores do Kafka. Os consumidores dentro do grupo revesam no consumo de mensagens do tópico. Aqui definimos *consumidor-usuarios* como identificador do grupo.\n",
    "- `auto.offset.reset`: define o offset de consumo de mensagens, ou seja, a partir de quando iremos ler mensagens do Kafka. Aqui definimos `earliest`, ou seja, iremos consumir todas as mensagens do tópico. Se colocarmos, por exemplo, `latest` iríamos consumir apenas as mensagens que chegarem daqui pra frente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer=Consumer({'bootstrap.servers':'kafka:9092','group.id':'consumidor-usuarios','auto.offset.reset':'earliest'})\n",
    "print('Kafka Consumer foi inicializado...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ler mensagens de um tópico, o consumidor deve se inscrever no tópico. No código abaixo o consumidor faz a inscrição no tópico `usuarios`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tópicos disponíveis: ', consumer.list_topics().topics)\n",
    "consumer.subscribe(['usuarios'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de inscrito no tópico chegou o momento de ler mensagens do tópico. O código abaixo itera no tópico `usuarios` lendo todas as mensagens. Quando não houver mais mensagens para serem lidas, o loop finaliza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # consome uma mensagem do tópico (espera 1 segundo)\n",
    "    msg=consumer.poll(1.0) #timeout\n",
    "    # Se a mensagem for nula é porque não existem mais mensagens.\n",
    "    # Neste caso, sai do loop\n",
    "    if msg is None:\n",
    "        break\n",
    "    \n",
    "    # Se tiver erro na mensagem lida, imprime a mensagem e continua o loop.\n",
    "    if msg.error():\n",
    "        print('Erro: {}'.format(msg.error()))\n",
    "        continue\n",
    "    \n",
    "    # lê o valor da mensagem\n",
    "    data=msg.value().decode('utf-8')\n",
    "    #imprime cada mensagem do tópico\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de lida todas as mensagens do tópico, o consumidor fecha a conexão com o Kafka no código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa\n",
    "\n",
    "Agora chegou sua vez de escrever e ler mensagens de um tópico do Kafka! Nesta tarefa você deve:\n",
    "\n",
    "- **Produtor**: escrever 20 mensagens no tópico `alunos` do Kafka. Faça um flush ao final da escrita.\n",
    "- **Consumidor**: ler as 20 mensagens do tópico `alunos` do Kafka. O `group-id` deve ser 'consumidor-alunos'. Feche a conexão com o Kafka ao final da leitura.\n",
    "- Cada mensagem deve ser construída da seguinte forma:\n",
    "\n",
    "\n",
    "```code\n",
    "data={\n",
    "       'id_aluno': fake.random_int(min=20000, max=100000),\n",
    "       'nome_aluno':fake.name(),\n",
    "       'endereco_aluno':fake.street_address() + ' | ' + fake.city() + ' | ' + fake.country_code(),\n",
    "       'nota_aluno': fake.random_int(min=0, max=100)\n",
    "       }\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
